# -*- coding: utf-8 -*-
"""K-means clustering algorithm .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcDZeqrlHySei6fOyOlb7QcDRwq-RIZU
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv('Mall_Customers.csv')

# Display the first few rows of the dataset along with column names
print(data.head())
print(data.columns) # Print the actual column names

# Select relevant features - Adjust these names based on the output of data.columns
features = data[['Annual Income (k$)', 'Spending Score (1-100)', 'Age']]

# Standardize the features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

"""Applying K-Means Clustering"""

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Determine the optimal number of clusters using the elbow method
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_features)
    sse.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.title('Elbow Method for Optimal Number of Clusters')
plt.show()

"""Training K- Means"""

# Apply K-means clustering
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(scaled_features)

# Add the cluster labels to the original dataset
data['Cluster'] = clusters

# Display the first few rows with cluster labels
print(data.head())

"""Evaluation

"""

import seaborn as sns

# Visualize the clusters
plt.figure(figsize=(12, 8))

# Verify the correct column name and use it below
# If the column name is different, replace 'CorrectColumnName' with the actual name
sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', data=data, palette='viridis', s=100)

plt.title('Customer Clusters based on Purchase History')
plt.show()